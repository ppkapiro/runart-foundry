name: "Deploy Briefing to Pages (Direct Upload)"

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging

permissions:
  contents: read
  id-token: write

jobs:
  deploy-direct:
    name: Build & Deploy via Wrangler Direct Upload
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment || 'production' }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          # Root level - no package.json exists, skip
          # Python deps
          pip install -r requirements.txt
      
      - name: Build Briefing
        run: |
          cd apps/briefing
          npm ci
          # Build with MkDocs (Python tool, not npm)
          mkdocs build -d site
        env:
          NODE_ENV: production
      
      - name: Verify build output
        run: |
          echo "=== Build output verification ==="
          ls -lh apps/briefing/site/
          echo ""
          echo "=== index.html preview ==="
          head -n 20 apps/briefing/site/index.html
          echo ""
          echo "=== Build size ==="
          du -sh apps/briefing/site/
      
      - name: Install Wrangler
        run: npm install -g wrangler
      
      - name: Resolve Account and Validate Token
        id: resolve_account
        run: |
          set -e

          mkdir -p docs/_meta/_deploy_forensics/post_migration

          echo "=== Resolve Account via wrangler whoami ==="
          WHOAMI_JSON=$(wrangler whoami --json || echo "{}")
          echo "$WHOAMI_JSON" | jq '.' > /tmp/whoami.json
          ACCOUNT_ID_RUNTIME=$(echo "$WHOAMI_JSON" | jq -r '.account_id // empty')

          ACCOUNT_ID_ENV="${CLOUDFLARE_ACCOUNT_ID:-}"
          if [ -n "$ACCOUNT_ID_ENV" ] && [ -n "$ACCOUNT_ID_RUNTIME" ] && [ "$ACCOUNT_ID_ENV" != "$ACCOUNT_ID_RUNTIME" ]; then
            echo "âš ï¸ WARNING: CLOUDFLARE_ACCOUNT_ID != wrangler whoami account_id ($ACCOUNT_ID_ENV vs $ACCOUNT_ID_RUNTIME). Using runtime value."
          fi
          ACCOUNT_ID_EFFECTIVE=${ACCOUNT_ID_RUNTIME:-$ACCOUNT_ID_ENV}
          if [ -z "$ACCOUNT_ID_EFFECTIVE" ]; then
            echo "âŒ ERROR: Unable to resolve Cloudflare Account ID (no env and whoami returned empty)."
            exit 1
          fi

          echo "ACCOUNT_ID_EFFECTIVE=$ACCOUNT_ID_EFFECTIVE" >> $GITHUB_ENV
          echo "ACCOUNT_ID_EFFECTIVE=$ACCOUNT_ID_EFFECTIVE" >> $GITHUB_OUTPUT

          echo "=== Verify Token via API ==="
          VERIFY=$(curl -s -X GET \
            "https://api.cloudflare.com/client/v4/user/tokens/verify" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
            -H "Content-Type: application/json")
          echo "$VERIFY" | jq '.' > docs/_meta/_deploy_forensics/post_migration/token_verify.json

          SUCCESS=$(echo "$VERIFY" | jq -r '.success // false')
          if [ "$SUCCESS" != "true" ]; then
            echo "âŒ ERROR: Token verification failed (success!=true)."
            head -c 400 docs/_meta/_deploy_forensics/post_migration/token_verify.json || true
            exit 1
          fi
          HAS_PAGES=$(echo "$VERIFY" | jq -r '. | tostring | test("pages"; "i")')
          if [ "$HAS_PAGES" != "true" ]; then
            echo "âŒ ERROR: Token does not appear to include Pages permissions (no 'pages' found in verify response)."
            exit 1
          fi
          echo "âœ… Token verify OK; Pages permissions likely present."
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CF_API_TOKEN_PAGES || secrets.CLOUDFLARE_API_TOKEN || secrets.CF_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID || secrets.CLOUDFLARE_ACCOUNT_ID }}

      - name: Check or Create Project (API)
        id: check_project
        run: |
          set -e
          PROJECT_NAME="runart-briefing-direct"
          ACCOUNT_ID="$ACCOUNT_ID_EFFECTIVE"

          echo "=== Check Project existence (API) ==="
          HTTP_STATUS=$(curl -s -o /tmp/project_get.json -w "%{http_code}" \
            -X GET "https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/pages/projects/$PROJECT_NAME" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
            -H "Content-Type: application/json")

          mkdir -p docs/_meta/_deploy_forensics/post_migration
          if [ "$HTTP_STATUS" = "200" ]; then
            echo "âœ… Project exists"
            cp /tmp/project_get.json docs/_meta/_deploy_forensics/post_migration/project_get.json
          elif [ "$HTTP_STATUS" = "404" ]; then
            echo '{"hint":"project will be created by wrangler"}' > /tmp/project_get.json
            cp /tmp/project_get.json docs/_meta/_deploy_forensics/post_migration/project_get.json
            echo "â„¹ï¸ Project not found (404). Wrangler will create it during deploy."
          else
            echo "âŒ ERROR: Invalid account or token scope when querying project (HTTP $HTTP_STATUS)."
            head -c 400 /tmp/project_get.json || true
            # Guardar de todas formas
            cp /tmp/project_get.json docs/_meta/_deploy_forensics/post_migration/project_get.json || true
            exit 1
          fi
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CF_API_TOKEN_PAGES || secrets.CLOUDFLARE_API_TOKEN || secrets.CF_API_TOKEN }}

      - name: Deploy to Cloudflare Pages (Direct Upload)
        id: deploy
        run: |
          set -e
          
          PROJECT_NAME="runart-briefing-direct"
          BRANCH="production"
          COMMIT_HASH="${{ github.sha }}"
          COMMIT_MSG="direct-upload:${COMMIT_HASH}"
          
          echo "=== Deploying to Cloudflare Pages via Direct Upload ==="
          echo "Project: $PROJECT_NAME"
          echo "Branch: $BRANCH"
          echo "Commit: $COMMIT_HASH"
          echo ""
          
          # Deploy with Wrangler
          OUTPUT=$(wrangler pages deploy "apps/briefing/site" \
            --project-name "$PROJECT_NAME" \
            --branch "$BRANCH" \
            --commit-hash "$COMMIT_HASH" \
            --commit-message "$COMMIT_MSG" 2>&1 | tee /tmp/wrangler_output.log)
          
          # Extract URL from output
          DEPLOY_URL=$(echo "$OUTPUT" | grep -oP 'https://[a-z0-9-]+\.runart-briefing-direct\.pages\.dev' | head -1)
          if [ -z "$DEPLOY_URL" ]; then
            DEPLOY_URL=$(echo "$OUTPUT" | grep -oP 'https://runart-briefing-direct\.pages\.dev' | head -1)
          fi
          
          echo "DEPLOY_URL=$DEPLOY_URL" >> $GITHUB_OUTPUT
          echo ""
          echo "âœ… Deploy completed"
          echo "URL: $DEPLOY_URL"
          mkdir -p docs/_meta/_deploy_forensics/post_migration
          cp /tmp/wrangler_output.log docs/_meta/_deploy_forensics/post_migration/wrangler_deploy.log || true
        env:
          # Fallbacks: soportar nombres de secretos existentes
          CLOUDFLARE_API_TOKEN: ${{ secrets.CF_API_TOKEN_PAGES || secrets.CLOUDFLARE_API_TOKEN || secrets.CF_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID || secrets.CLOUDFLARE_ACCOUNT_ID }}
      
      - name: Query deployment info via Wrangler
        id: deployment_info
        run: |
          set -e
          
          PROJECT_NAME="runart-briefing-direct"
          
          echo "=== Querying latest deployment ==="
          wrangler pages deployment list --project-name "$PROJECT_NAME" | head -20 | tee /tmp/deployments.txt
          
          # Try to extract deployment ID
          DEPLOYMENT_ID=$(grep -oP '[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}' /tmp/deployments.txt | head -1 || echo "")
          
          echo "DEPLOYMENT_ID=$DEPLOYMENT_ID" >> $GITHUB_OUTPUT
          echo ""
          echo "Deployment ID: $DEPLOYMENT_ID"
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CF_API_TOKEN_PAGES || secrets.CLOUDFLARE_API_TOKEN || secrets.CF_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID || secrets.CLOUDFLARE_ACCOUNT_ID }}
        continue-on-error: true
      
      - name: Verify deployment source via API
        id: verify_source
        run: |
          set -e
          
          PROJECT_NAME="runart-briefing-direct"
          ACCOUNT_ID="$ACCOUNT_ID_EFFECTIVE"
          
          echo "=== Verifying deployment source ==="
          echo "Waiting up to ~60 seconds for API to update..."
          sleep 10
          
          # Query latest deployment (with retry)
          MAX_RETRIES=5
          RETRY=0
          while [ $RETRY -lt $MAX_RETRIES ]; do
            RESPONSE=$(curl -s -X GET \
              "https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/pages/projects/$PROJECT_NAME/deployments?per_page=1&branch=production" \
              -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
              -H "Content-Type: application/json")
            
            SUCCESS=$(echo "$RESPONSE" | jq -r '.success // false')
            SOURCE=$(echo "$RESPONSE" | jq -r '.result[0].source.type // empty')
            TRIGGER=$(echo "$RESPONSE" | jq -r '.result[0].deployment_trigger.type // empty')
            CREATED_AT=$(echo "$RESPONSE" | jq -r '.result[0].created_on // empty')
            # Normalizar fuente a DIRECT_UPLOAD_OK/UNKNOWN
            NORMALIZED="UNKNOWN"
            if [ "$SOURCE" = "direct_upload" ] || [ "$SOURCE" = "api" ] || [ "$SOURCE" = "ad_hoc" ]; then
              NORMALIZED="DIRECT_UPLOAD_OK"
            elif [ "$TRIGGER" = "ad_hoc" ] || [ "$TRIGGER" = "api" ]; then
              NORMALIZED="DIRECT_UPLOAD_OK"
            fi
            
            if [ "$SUCCESS" = "true" ] && [ "$NORMALIZED" != "UNKNOWN" ]; then
              break
            fi
            
            RETRY=$((RETRY + 1))
            if [ $RETRY -lt $MAX_RETRIES ]; then
              echo "Source still unknown or API not ready (attempt $((RETRY + 1))/$MAX_RETRIES)... waiting 10s"
              sleep 10
            fi
          done
          
          echo "$RESPONSE" | jq '.' > /tmp/deployments_api.json
          
          # Extract details
          DEPLOY_ID=$(echo "$RESPONSE" | jq -r '.result[0].id // "unknown"')
          COMMIT=$(echo "$RESPONSE" | jq -r '.result[0].deployment_trigger.metadata.commit_hash // "unknown"')
          
          # Exponer salidas: raw/trigger/normalized y created_at
          echo "SOURCE_RAW=$SOURCE" >> $GITHUB_OUTPUT
          echo "TRIGGER_TYPE=$TRIGGER" >> $GITHUB_OUTPUT
          echo "SOURCE_NORMALIZED=$NORMALIZED" >> $GITHUB_OUTPUT
          echo "CREATED_AT=$CREATED_AT" >> $GITHUB_OUTPUT
          echo "DEPLOY_ID=$DEPLOY_ID" >> $GITHUB_OUTPUT
          echo ""
          echo "âœ… Source verification completed"
          echo "Source (normalized): $NORMALIZED"
          echo "Source (raw): ${SOURCE:-empty} | Trigger: ${TRIGGER:-empty} | Success: $SUCCESS"
          echo "Deployment ID: $DEPLOY_ID"
          echo "Commit: $COMMIT"
          
          # Validate source
          if [ "$NORMALIZED" != "DIRECT_UPLOAD_OK" ]; then
            echo "âŒ ERROR: Expected SOURCE_NORMALIZED=DIRECT_UPLOAD_OK, got ${NORMALIZED} (raw=${SOURCE:-empty}, trigger=${TRIGGER:-empty})"
            echo "This may indicate timing issues, wrong Account ID/Token scope, or Git Integration interference."
            echo "--- API response (first 400 chars) ---"
            echo "$RESPONSE" | head -c 400 || true
            echo "\n--- end ---"
            exit 1
          fi
          
          echo "âœ… Source validation PASSED (DIRECT_UPLOAD_OK)"
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CF_API_TOKEN_PAGES || secrets.CLOUDFLARE_API_TOKEN || secrets.CF_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID || secrets.CLOUDFLARE_ACCOUNT_ID }}
      
      - name: Record deployment evidence
        if: always()
        run: |
          mkdir -p docs/_meta/_deploy_forensics/post_migration
          
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          
          cat > docs/_meta/_deploy_forensics/post_migration/pre_cutover.md <<EOF
          # MigraciÃ³n a Direct Upload â€” Pre-Cutover Evidence
          
          **Fecha**: $TIMESTAMP
          **Workflow Run**: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          **Commit**: ${{ github.sha }}
          
          ## Deployment Info
          
          - **Project Name**: runart-briefing-direct
          - **Branch**: production
          - **Deploy URL**: ${{ steps.deploy.outputs.DEPLOY_URL }}
          - **Deployment ID**: ${{ steps.verify_source.outputs.DEPLOY_ID }}
          - **Source Type (normalized)**: ${{ steps.verify_source.outputs.SOURCE_NORMALIZED }}
          - **Source Type (raw)**: ${{ steps.verify_source.outputs.SOURCE_RAW }}
          - **Trigger Type**: ${{ steps.verify_source.outputs.TRIGGER_TYPE }}
          - **Created At**: ${{ steps.verify_source.outputs.CREATED_AT }}
          
          ## Validation Results
          
          - âœ… Build completed successfully
          - âœ… Wrangler deploy completed
          - âœ… Source verification: **${{ steps.verify_source.outputs.SOURCE_NORMALIZED || 'N/A' }}**
          - â­ï¸ Access validation: PENDING (requires manual policy setup)
          - â­ï¸ Fingerprint comparison: PENDING
          
          ## Next Steps
          
          1. Owner must add new hostname to Access app "RUN Briefing"
          2. Validate Access with Service Token
          3. Compare fingerprints
          4. Plan cutover
          
          EOF
          
          # Copy API response
          cp /tmp/deployments_api.json docs/_meta/_deploy_forensics/post_migration/deployment_api_response.json || true
          cp /tmp/wrangler_output.log docs/_meta/_deploy_forensics/post_migration/wrangler_deploy.log || true
          
          echo "âœ… Evidence recorded in docs/_meta/_deploy_forensics/post_migration/"
      
      - name: Access Check â€” Discover asset
        id: find_asset
        if: always()
        run: |
          set -e
          # Pick first CSS/JS asset from local build to mirror in prod
          ASSET=$(find apps/briefing/site -type f \( -name '*.css' -o -name '*.js' \) | sed 's#apps/briefing/site/##' | head -1 || true)
          echo "ASSET_REL=$ASSET" >> $GITHUB_OUTPUT
          echo "ASSET_REL=$ASSET" >> $GITHUB_ENV

      - name: Access Check â€” With Headers (200 expected)
        if: always()
        run: |
          set -e
          mkdir -p docs/_meta
          URL="${{ steps.deploy.outputs.DEPLOY_URL }}"
          if [ -z "$URL" ]; then echo "No DEPLOY_URL, skipping"; exit 0; fi
          if [ -z "${{ secrets.CF_ACCESS_CLIENT_ID }}" ] || [ -z "${{ secrets.CF_ACCESS_CLIENT_SECRET }}" ]; then
            echo "PENDING_PROTECTION: Missing Access secrets" >> docs/_meta/ACCESS_DIAG_BRIEFING.md
            exit 0
          fi
          {
            echo "# Nuevo proyecto â€” protegido (with headers)"
            echo "Root: $URL"
          } >> docs/_meta/ACCESS_DIAG_BRIEFING.md
          # HEAD root
          curl -s -I "$URL/" \
            -H "CF-Access-Client-Id: ${{ secrets.CF_ACCESS_CLIENT_ID }}" \
            -H "CF-Access-Client-Secret: ${{ secrets.CF_ACCESS_CLIENT_SECRET }}" \
            | tee -a docs/_meta/ACCESS_DIAG_BRIEFING.md
          # HEAD asset
          if [ -n "$ASSET_REL" ]; then
            echo "\nAsset: $URL/$ASSET_REL" >> docs/_meta/ACCESS_DIAG_BRIEFING.md
            curl -s -I "$URL/$ASSET_REL" \
              -H "CF-Access-Client-Id: ${{ secrets.CF_ACCESS_CLIENT_ID }}" \
              -H "CF-Access-Client-Secret: ${{ secrets.CF_ACCESS_CLIENT_SECRET }}" \
              | tee -a docs/_meta/ACCESS_DIAG_BRIEFING.md
          fi

      - name: Access Check â€” Without Headers (blocked expected)
        if: always()
        run: |
          set -e
          mkdir -p docs/_meta
          URL="${{ steps.deploy.outputs.DEPLOY_URL }}"
          if [ -z "$URL" ]; then echo "No DEPLOY_URL, skipping"; exit 0; fi
          {
            echo "\n# Nuevo proyecto â€” protegido (without headers)"
            echo "Root: $URL"
          } >> docs/_meta/ACCESS_DIAG_BRIEFING.md
          curl -s -I "$URL/" | tee -a docs/_meta/ACCESS_DIAG_BRIEFING.md
          if [ -n "$ASSET_REL" ]; then
            echo "\nAsset: $URL/$ASSET_REL" >> docs/_meta/ACCESS_DIAG_BRIEFING.md
            curl -s -I "$URL/$ASSET_REL" | tee -a docs/_meta/ACCESS_DIAG_BRIEFING.md
          fi

      - name: Fingerprints â€” Local and Prod
        id: fingerprints
        if: always()
        run: |
          set -e
          mkdir -p docs/_meta/_deploy_forensics/post_migration
          URL="${{ steps.deploy.outputs.DEPLOY_URL }}"
          INDEX_LOCAL="apps/briefing/site/index.html"
          ASSET_REL="${ASSET_REL:-}"
          ASSET_LOCAL="apps/briefing/site/${ASSET_REL:-}"

          # Local hashes
          INDEX_SHA_LOCAL=$(sha256sum "$INDEX_LOCAL" | awk '{print $1}')
          ASSET_SHA_LOCAL=""
          if [ -f "$ASSET_LOCAL" ]; then
            ASSET_SHA_LOCAL=$(sha256sum "$ASSET_LOCAL" | awk '{print $1}')
          fi
          jq -n --arg index "$INDEX_SHA_LOCAL" --arg asset "$ASSET_SHA_LOCAL" '{index_sha:$index,asset_sha:$asset}' \
            > docs/_meta/_deploy_forensics/post_migration/fp_local.json

          # Prod fetch (with Access headers if present)
          HDR_ID="${{ secrets.CF_ACCESS_CLIENT_ID }}"
          HDR_SECRET="${{ secrets.CF_ACCESS_CLIENT_SECRET }}"
          CURL_HDRS=()
          if [ -n "$HDR_ID" ] && [ -n "$HDR_SECRET" ]; then
            CURL_HDRS+=( -H "CF-Access-Client-Id: $HDR_ID" -H "CF-Access-Client-Secret: $HDR_SECRET" )
          fi

          INDEX_ETAG=$(curl -s -D - "$URL/" "${CURL_HDRS[@]}" -o /dev/null | grep -i '^etag:' | head -1 | cut -d' ' -f2- | tr -d '\r\n' || true)
          INDEX_SHA_PROD=$(curl -s "$URL/" "${CURL_HDRS[@]}" | sha256sum | awk '{print $1}')
          ASSET_ETAG=""
          ASSET_SHA_PROD=""
          if [ -n "$ASSET_REL" ]; then
            ASSET_ETAG=$(curl -s -D - "$URL/$ASSET_REL" "${CURL_HDRS[@]}" -o /dev/null | grep -i '^etag:' | head -1 | cut -d' ' -f2- | tr -d '\r\n' || true)
            ASSET_SHA_PROD=$(curl -s "$URL/$ASSET_REL" "${CURL_HDRS[@]}" | sha256sum | awk '{print $1}')
          fi
          jq -n \
            --arg index_etag "$INDEX_ETAG" --arg index_sha "$INDEX_SHA_PROD" \
            --arg asset_etag "$ASSET_ETAG" --arg asset_sha "$ASSET_SHA_PROD" \
            '{index_etag:$index_etag,index_sha:$index_sha,asset_etag:$asset_etag,asset_sha:$asset_sha}' \
            > docs/_meta/_deploy_forensics/post_migration/fp_prod.json

          # Compare
          STATUS="MATCH"
          if [ "$INDEX_SHA_LOCAL" != "$INDEX_SHA_PROD" ] || { [ -n "$ASSET_SHA_LOCAL" ] && [ "$ASSET_SHA_LOCAL" != "$ASSET_SHA_PROD" ]; }; then
            STATUS="MISMATCH"
          fi
          echo "$STATUS" > /tmp/fp_status
          {
            echo "Fingerprint compare: $STATUS"
            echo "index local=$INDEX_SHA_LOCAL prod=$INDEX_SHA_PROD"
            if [ -n "$ASSET_SHA_LOCAL" ]; then echo "asset local=$ASSET_SHA_LOCAL prod=$ASSET_SHA_PROD"; fi
          } > docs/_meta/_deploy_forensics/post_migration/fingerprint_diff.txt

      - name: Fingerprints â€” Optional Purge and Retry
        if: always()
        run: |
          set -e
          URL="${{ steps.deploy.outputs.DEPLOY_URL }}"
          STATUS=$(cat /tmp/fp_status || echo "UNKNOWN")
          if [ "$STATUS" != "MISMATCH" ]; then echo "No mismatch, skip purge"; exit 0; fi
          ZONE_ID="${{ secrets.CF_ZONE_ID || secrets.CLOUDFLARE_ZONE_ID }}"
          if [ -z "$ZONE_ID" ]; then
            echo "No ZONE_ID available, cannot purge. Recording MISMATCH_after_purge." >> docs/_meta/_deploy_forensics/post_migration/fingerprint_diff.txt
            exit 0
          fi
          FILES_JSON=$(jq -n --arg url "$URL/" --arg asset "$ASSET_REL" '{files: [$url, ($asset|length>0?($url+$asset):empty)] | map(select(. != null and . != "")) }')
          echo "$FILES_JSON" > /tmp/purge.json
          RESP=$(curl -s -X POST "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" -H "Content-Type: application/json" \
            --data @/tmp/purge.json)
          echo "$RESP" | head -c 400
          sleep 5
          # Re-fetch index only
          HDR_ID="${{ secrets.CF_ACCESS_CLIENT_ID }}"; HDR_SECRET="${{ secrets.CF_ACCESS_CLIENT_SECRET }}"; CURL_HDRS=()
          if [ -n "$HDR_ID" ] && [ -n "$HDR_SECRET" ]; then CURL_HDRS+=( -H "CF-Access-Client-Id: $HDR_ID" -H "CF-Access-Client-Secret: $HDR_SECRET" ); fi
          INDEX_SHA_PROD2=$(curl -s "$URL/" "${CURL_HDRS[@]}" | sha256sum | awk '{print $1}')
          echo "After purge index sha: $INDEX_SHA_PROD2" >> docs/_meta/_deploy_forensics/post_migration/fingerprint_diff.txt
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CF_API_TOKEN_PAGES || secrets.CLOUDFLARE_API_TOKEN || secrets.CF_API_TOKEN }}

      - name: Commit evidence
        if: always()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          git add docs/_meta/_deploy_forensics/post_migration/
          git add docs/_meta/ACCESS_DIAG_BRIEFING.md || true
          git add docs/_meta/BRIEFING_STATUS_PIPELINE_RUN.md || true
          git add docs/_meta/BRIEFING_DEPLOY_HANDOFF.md || true
          git add docs/_meta/WORKFLOW_AUDIT_DEPLOY.md || true
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "migration: direct upload deployment evidence [skip ci]"
            git push
          fi
        continue-on-error: true
      
      - name: Summary
        if: always()
        run: |
          echo "## ðŸš€ Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Project**: runart-briefing-direct" >> $GITHUB_STEP_SUMMARY
          echo "**URL**: ${{ steps.deploy.outputs.DEPLOY_URL }}" >> $GITHUB_STEP_SUMMARY
          echo "**Source (normalized)**: ${{ steps.verify_source.outputs.SOURCE_NORMALIZED }}" >> $GITHUB_STEP_SUMMARY
          echo "**Source (raw)**: ${{ steps.verify_source.outputs.SOURCE_RAW }} | **Trigger**: ${{ steps.verify_source.outputs.TRIGGER_TYPE }}" >> $GITHUB_STEP_SUMMARY
          echo "**Deployment ID**: ${{ steps.verify_source.outputs.DEPLOY_ID }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.verify_source.outputs.SOURCE_NORMALIZED }}" = "DIRECT_UPLOAD_OK" ]; then
            echo "âœ… **Status**: Direct Upload deployment successful" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ **Status**: Deployment finished but source verification did not confirm direct_upload" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Update BRIEFING_STATUS_PIPELINE_RUN.md
        if: always()
        run: |
          set -e
          FILE="docs/_meta/BRIEFING_STATUS_PIPELINE_RUN.md"
          mkdir -p "$(dirname "$FILE")"
          {
            echo "\n---\n## Direct Upload â€” Ãºltima ejecuciÃ³n"
            echo "- Fecha: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
            echo "- Run URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            echo "- Proyecto: runart-briefing-direct"
            echo "- URL: ${{ steps.deploy.outputs.DEPLOY_URL }}"
            echo "- SOURCE_NORMALIZED: ${{ steps.verify_source.outputs.SOURCE_NORMALIZED }} (raw=${{ steps.verify_source.outputs.SOURCE_RAW }}, trigger=${{ steps.verify_source.outputs.TRIGGER_TYPE }})"
            echo "- Deployment ID: ${{ steps.verify_source.outputs.DEPLOY_ID }}"
          } >> "$FILE"

      - name: Create Cutover Plan doc
        if: always()
        run: |
          set -e
          FILE="docs/_meta/BRIEFING_DEPLOY_HANDOFF.md"
          mkdir -p docs/_meta
          if [ ! -f "$FILE" ]; then
            cat > "$FILE" << 'EOF'
            # Briefing â€” Cutover Plan (Direct Upload)

            Opciones de corte:

            - OpciÃ³n 1: Apuntar dominio custom (p.ej. briefing.runartfoundry.com) al proyecto nuevo `runart-briefing-direct` y retirar del antiguo.
            - OpciÃ³n 2: Ventana corta; eliminar proyecto viejo y re-crear con `--project-name "runart-foundry"` para conservar subdominio histÃ³rico; revalidar Access y bindings.

            Requisitos: ValidaciÃ³n API OK, Access (200 con headers, 302/403 sin headers), fingerprints MATCH.
            EOF
          fi

      - name: Append Workflow Audit note
        if: always()
        run: |
          set -e
          FILE="docs/_meta/WORKFLOW_AUDIT_DEPLOY.md"
          mkdir -p docs/_meta
          {
            echo "\n## MigraciÃ³n Direct Upload â€” $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
            echo "Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            echo "Project: runart-briefing-direct | URL: ${{ steps.deploy.outputs.DEPLOY_URL }}"
            echo "SOURCE_NORMALIZED: ${{ steps.verify_source.outputs.SOURCE_NORMALIZED }} | RAW: ${{ steps.verify_source.outputs.SOURCE_RAW }} | TRIGGER: ${{ steps.verify_source.outputs.TRIGGER_TYPE }}"
          } >> "$FILE"
